### 初识Hadoop
* hadoop2.x的特性
    ```
    特性 | 安全认证 旧的配置项 新的配置项 旧的MR-API 新的MR-API MR1的运行环境 MR2的运行环境 HDFS联邦管理 HDFS的高可用
    ============================================================================================================
    2.x  | √        ×           √          √           √           ×              √             √            √   
    ```
### mapreduce
* 过程
    ```
    Input       =>      Map        =>      Shuffle         =>          Reduce        =>      Output
    ------------------------------------------------------------------------------------------------
    file等    (k11,v11)        (k21,v211)          (k21,[v211,v212,..])          (k21,v31)    file等
              (k12,v12)        (k21,v212)         (k22,[v221,..])               (k22,v32)
              ...              (k22,v221)          ...                           ...
                                ...
    ```
1. 输入
    * 分片（split）
        * MR将输入的数据划分成等长的小数据块，hadoop为每个分片创建一个map任务
        * 虽然分片被切的越细，负载均衡会更好。但是也要考虑最小化寻址开销，数据块大则块数据传输时间远大于块的寻址时间MR集群中的map数量，分片大小，分片/map数量要做权衡。
            同时，分片的大小也不能太大，太大就会导致一个分片跨越多个数据块。而**通常情况下这些多个数据块会存储在不同的
            主机上**。（跟数据块副本落在不同的主机上类似，就是为了减少数据丢失的可能）
        * **合理的分片大小就是将分片大小设置为hdfs的块大小**，而一个hdfs文件若小于hdfs的块大小，
            则其逻辑占据一个块大小，实际物理上占据的就是其真实大小。这也是为什么默认情况下，一个hdfs文件
            就是一个分片（这个hdfs文件大小小于一个hdfs的块大小）
    * 数据本地化优化
        * 原因：
            由于map执行在本机器上，而map需要的数据文件存储在其他主机上，则这个时候就要消耗网络带宽与传输时间。
        * 措施：
            * 故尽可能让执行MR的程序与其所需要的数据存在于同一物理主机上。
         
2. map
    * map输出的中间结果
        * 输出位置：执行这个map任务主机的本地磁盘上
            * 输出到本地磁盘的原因：map产生的只是中间结果，直接结果是供reduce使用产生最终结果的。
                一旦job完成，map的中间结果就会被删除。故不需要小题大做存储到hdfs上
    * 当传输map的中间结果之前，map就失败了
        * 解决方案：
            * 在MR集群的另一个主机上启动map任务来构建中间结果。（当然选定新的map任务节点肯定也
                优先考虑有map所需数据副本的主机上执行map任务）
    
                
3. shuffle

4. combine(可有可无)
    * 数据处理
        ```
        (k21, [v211,v212,v213,..])     combine      (k21, v212)
        (k22, [v221,v222,v223,..])   ===========>   (k22, v223)
        ...                                          ...
        ```
    * 将shuffle后的map输出先做一步处理类似reduce，目的是为了减少网络数据传输量。
5. reduce
    * reduce的输入通常来自一个或多个map的输出，**一般为了可靠性将最终结果放在hdfs存储**
        * 结果的存储执行hdfs副本存储策略：1.存储在本地节点上 2.存储在同一机架上的其他节点上 3.存储在其他机架上任意节点上
        
6. 输出
